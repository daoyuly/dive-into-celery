# Celery å¤šè¿›ç¨‹ç®¡ç†å·¥å…·è¯¦è§£

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒå·¥å…·ï¼šBilliard](#æ ¸å¿ƒå·¥å…·billiard)
2. [Billiard vs Multiprocessing](#billiard-vs-multiprocessing)
3. [è¿›ç¨‹æ± å®ç°æœºåˆ¶](#è¿›ç¨‹æ± å®ç°æœºåˆ¶)
4. [è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†](#è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†)
5. [è¿›ç¨‹é—´é€šä¿¡](#è¿›ç¨‹é—´é€šä¿¡)
6. [æºç çº§å®ç°åˆ†æ](#æºç çº§å®ç°åˆ†æ)
7. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ ¸å¿ƒå·¥å…·ï¼šBilliard

### ä»€ä¹ˆæ˜¯ Billiardï¼Ÿ

**Billiard** æ˜¯ Celery ä½¿ç”¨çš„å¤šè¿›ç¨‹ç®¡ç†åº“ï¼Œå®ƒæ˜¯ Python æ ‡å‡†åº“ `multiprocessing` çš„ä¸€ä¸ª **forkï¼ˆåˆ†æ”¯ï¼‰**ï¼Œä¸“é—¨ä¸º Celery ä¼˜åŒ–ã€‚

### ä¸ºä»€ä¹ˆä½¿ç”¨ Billiard è€Œä¸æ˜¯ Multiprocessingï¼Ÿ

1. **å…¼å®¹æ€§ä¼˜åŒ–**ï¼šBilliard ä¿®å¤äº† `multiprocessing` åœ¨æŸäº›å¹³å°ä¸Šçš„å…¼å®¹æ€§é—®é¢˜
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šé’ˆå¯¹ Celery çš„ä½¿ç”¨åœºæ™¯è¿›è¡Œäº†æ€§èƒ½ä¼˜åŒ–
3. **åŠŸèƒ½å¢å¼º**ï¼šæ·»åŠ äº†ä¸€äº› Celery éœ€è¦çš„ç‰¹æ®ŠåŠŸèƒ½
4. **ç»´æŠ¤æ€§**ï¼šCelery å›¢é˜Ÿå¯ä»¥ç‹¬ç«‹ç»´æŠ¤å’Œä¼˜åŒ–

### Billiard çš„å®‰è£…

Billiard æ˜¯ Celery çš„ä¾èµ–ï¼Œå®‰è£… Celery æ—¶ä¼šè‡ªåŠ¨å®‰è£…ï¼š

```bash
pip install celery
# ä¼šè‡ªåŠ¨å®‰è£… billiard
```

### æ£€æŸ¥ Billiard ç‰ˆæœ¬

```python
import billiard
print(billiard.__version__)
```

---

## Billiard vs Multiprocessing

### å…³ç³»

```
multiprocessing (Python æ ‡å‡†åº“)
    â”‚
    â””â”€ fork â”€â”€â†’ billiard (Celery ä¸“ç”¨ fork)
                    â”‚
                    â””â”€ ä¼˜åŒ–å’Œå¢å¼º
```

### ä¸»è¦åŒºåˆ«

| ç‰¹æ€§ | Multiprocessing | Billiard |
|------|----------------|----------|
| **æ¥æº** | Python æ ‡å‡†åº“ | Celery ç»´æŠ¤çš„ fork |
| **å…¼å®¹æ€§** | æ ‡å‡†å®ç° | ä¿®å¤äº†æŸäº›å¹³å°çš„å…¼å®¹æ€§é—®é¢˜ |
| **æ€§èƒ½** | æ ‡å‡†æ€§èƒ½ | é’ˆå¯¹ Celery ä¼˜åŒ– |
| **åŠŸèƒ½** | åŸºç¡€åŠŸèƒ½ | æ·»åŠ äº† Celery éœ€è¦çš„åŠŸèƒ½ |
| **ç»´æŠ¤** | Python æ ¸å¿ƒå›¢é˜Ÿ | Celery å›¢é˜Ÿ |

### ä»£ç å±‚é¢çš„å·®å¼‚

```python
# Multiprocessing (æ ‡å‡†åº“)
from multiprocessing import Process, Pool

# Billiard (Celery ä½¿ç”¨)
from billiard import Process, Pool

# API åŸºæœ¬ç›¸åŒï¼Œä½†å†…éƒ¨å®ç°æœ‰ä¼˜åŒ–
```

---

## è¿›ç¨‹æ± å®ç°æœºåˆ¶

### 1. Prefork Pool æ¶æ„

Celery ä½¿ç”¨ Billiard çš„ `Pool` ç±»å®ç° Prefork è¿›ç¨‹æ± ï¼š

```python
# Celery å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
from billiard import Pool

class PreforkPool:
    def __init__(self, processes=None):
        # åˆ›å»ºè¿›ç¨‹æ± 
        self.pool = Pool(processes=processes)
        self.processes = processes
    
    def apply_async(self, func, args=(), kwds={}):
        """å¼‚æ­¥æ‰§è¡Œä»»åŠ¡"""
        return self.pool.apply_async(func, args, kwds)
    
    def close(self):
        """å…³é—­è¿›ç¨‹æ± ï¼ˆä¸å†æ¥å—æ–°ä»»åŠ¡ï¼‰"""
        self.pool.close()
    
    def terminate(self):
        """ç«‹å³ç»ˆæ­¢æ‰€æœ‰è¿›ç¨‹"""
        self.pool.terminate()
    
    def join(self):
        """ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ"""
        self.pool.join()
```

### 2. è¿›ç¨‹åˆ›å»ºæµç¨‹

```
1. ä¸»è¿›ç¨‹å¯åŠ¨
   â†“
2. åˆ›å»º PreforkPool å¯¹è±¡
   â†“
3. Billiard Pool åˆå§‹åŒ–
   â†“
4. Fork å­è¿›ç¨‹ï¼ˆ--concurrency=Nï¼‰
   â”œâ”€ fork() â†’ å­è¿›ç¨‹ 1
   â”œâ”€ fork() â†’ å­è¿›ç¨‹ 2
   â”œâ”€ fork() â†’ å­è¿›ç¨‹ 3
   â””â”€ fork() â†’ å­è¿›ç¨‹ N
   â†“
5. å­è¿›ç¨‹è¿›å…¥å·¥ä½œå¾ªç¯
   â””â”€ ç­‰å¾…ä»»åŠ¡ â†’ æ‰§è¡Œä»»åŠ¡ â†’ è¿”å›ç»“æœ
```

### 3. è¿›ç¨‹æ± çŠ¶æ€ç®¡ç†

```python
# è¿›ç¨‹æ± çš„çŠ¶æ€
class PoolState:
    RUN = 0      # è¿è¡Œä¸­
    CLOSE = 1    # å…³é—­ä¸­ï¼ˆä¸å†æ¥å—æ–°ä»»åŠ¡ï¼‰
    TERMINATE = 2 # ç»ˆæ­¢ä¸­ï¼ˆå¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰è¿›ç¨‹ï¼‰
```

---

## è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†

### 1. è¿›ç¨‹åˆ›å»º

**Fork æœºåˆ¶**ï¼š

```python
# Billiard å†…éƒ¨ä½¿ç”¨ fork() ç³»ç»Ÿè°ƒç”¨
import os

def create_worker_process():
    """åˆ›å»º Worker å­è¿›ç¨‹"""
    pid = os.fork()
    
    if pid == 0:
        # å­è¿›ç¨‹
        worker_main_loop()  # è¿›å…¥å·¥ä½œå¾ªç¯
    else:
        # çˆ¶è¿›ç¨‹
        return pid  # è¿”å›å­è¿›ç¨‹ PID
```

**å†™æ—¶å¤åˆ¶ï¼ˆCOWï¼‰**ï¼š

- å­è¿›ç¨‹åˆ›å»ºæ—¶ï¼Œä¸ç«‹å³å¤åˆ¶çˆ¶è¿›ç¨‹çš„å†…å­˜
- çˆ¶å­è¿›ç¨‹å…±äº«åŒä¸€ä»½ç‰©ç†å†…å­˜é¡µï¼ˆåªè¯»ï¼‰
- åªæœ‰å½“å­è¿›ç¨‹å†™å…¥å†…å­˜æ—¶ï¼Œæ‰çœŸæ­£å¤åˆ¶è¯¥é¡µ

### 2. è¿›ç¨‹ç›‘æ§

**ä¸»è¿›ç¨‹ç›‘æ§å­è¿›ç¨‹**ï¼š

```python
# Celery ä¸»è¿›ç¨‹ç›‘æ§å­è¿›ç¨‹çš„å¥åº·çŠ¶æ€
import signal
import os

def monitor_worker_processes():
    """ç›‘æ§ Worker è¿›ç¨‹"""
    while True:
        for pid in worker_pids:
            try:
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
                os.kill(pid, 0)  # å‘é€ä¿¡å· 0ï¼ˆä¸å®é™…å‘é€ï¼Œåªæ£€æŸ¥ï¼‰
            except OSError:
                # è¿›ç¨‹å·²æ­»äº¡ï¼Œé‡å¯
                restart_worker(pid)
        
        time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
```

### 3. è¿›ç¨‹é‡å¯æœºåˆ¶

**è‡ªåŠ¨é‡å¯ç­–ç•¥**ï¼š

```python
# Celery çš„è¿›ç¨‹é‡å¯æœºåˆ¶
class WorkerProcess:
    def __init__(self, max_tasks_per_child=1000):
        self.max_tasks_per_child = max_tasks_per_child
        self.tasks_executed = 0
    
    def execute_task(self, task):
        """æ‰§è¡Œä»»åŠ¡"""
        result = task.run()
        self.tasks_executed += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
        if self.tasks_executed >= self.max_tasks_per_child:
            self.restart()  # é‡å¯è¿›ç¨‹ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        
        return result
    
    def restart(self):
        """é‡å¯è¿›ç¨‹"""
        # é€€å‡ºå½“å‰è¿›ç¨‹
        # ä¸»è¿›ç¨‹ä¼šæ£€æµ‹åˆ°å¹¶åˆ›å»ºæ–°è¿›ç¨‹
        os._exit(0)
```

### 4. è¿›ç¨‹ç»ˆæ­¢

**ä¼˜é›…å…³é—­**ï¼š

```python
# ä¼˜é›…å…³é—­è¿›ç¨‹æ± 
def graceful_shutdown(pool):
    """ä¼˜é›…å…³é—­è¿›ç¨‹æ± """
    # 1. ä¸å†æ¥å—æ–°ä»»åŠ¡
    pool.close()
    
    # 2. ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ
    pool.join(timeout=30)
    
    # 3. å¦‚æœè¶…æ—¶ï¼Œå¼ºåˆ¶ç»ˆæ­¢
    if pool.is_alive():
        pool.terminate()
        pool.join()
```

**ä¿¡å·å¤„ç†**ï¼š

```python
import signal

def setup_signal_handlers(pool):
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
    def signal_handler(signum, frame):
        if signum == signal.SIGTERM:
            # ä¼˜é›…å…³é—­
            pool.close()
            pool.join()
        elif signum == signal.SIGINT:
            # ç«‹å³ç»ˆæ­¢
            pool.terminate()
            pool.join()
    
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
```

---

## è¿›ç¨‹é—´é€šä¿¡

### 1. ç®¡é“ï¼ˆPipeï¼‰

**ç”¨é€”**ï¼šä¸»è¿›ç¨‹å’Œå­è¿›ç¨‹ä¹‹é—´çš„åŒå‘é€šä¿¡

```python
from billiard import Pipe

# åˆ›å»ºç®¡é“
parent_conn, child_conn = Pipe()

# ä¸»è¿›ç¨‹å‘é€æ¶ˆæ¯
parent_conn.send("ä»»åŠ¡å®Œæˆ")

# å­è¿›ç¨‹æ¥æ”¶æ¶ˆæ¯
message = child_conn.recv()
```

**Celery ä¸­çš„ä½¿ç”¨**ï¼š

```python
# Celery ä½¿ç”¨ç®¡é“è¿›è¡Œè¿›ç¨‹é—´é€šä¿¡
# - ä¸»è¿›ç¨‹å‘é€å‘½ä»¤ï¼ˆé‡å¯ã€å…³é—­ï¼‰
# - å­è¿›ç¨‹å‘é€çŠ¶æ€ï¼ˆä»»åŠ¡å®Œæˆã€é”™è¯¯ï¼‰
```

### 2. é˜Ÿåˆ—ï¼ˆQueueï¼‰

**ç”¨é€”**ï¼šè¿›ç¨‹é—´ä¼ é€’ä»»åŠ¡å’Œç»“æœ

```python
from billiard import Queue

# åˆ›å»ºé˜Ÿåˆ—
task_queue = Queue()
result_queue = Queue()

# ä¸»è¿›ç¨‹å‘é€ä»»åŠ¡
task_queue.put(task)

# å­è¿›ç¨‹è·å–ä»»åŠ¡
task = task_queue.get()

# å­è¿›ç¨‹å‘é€ç»“æœ
result_queue.put(result)
```

### 3. å…±äº«å†…å­˜ï¼ˆé™åˆ¶ä½¿ç”¨ï¼‰

**æ³¨æ„**ï¼šCelery ä¸ç›´æ¥ä½¿ç”¨å…±äº«å†…å­˜
- åŸå› ï¼šä»»åŠ¡éš”ç¦»ï¼Œé¿å…ç«äº‰æ¡ä»¶
- æ¯ä¸ªè¿›ç¨‹æœ‰ç‹¬ç«‹çš„å†…å­˜ç©ºé—´

### 4. æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆRedis/RabbitMQï¼‰

**ç”¨é€”**ï¼šä»»åŠ¡åˆ†å‘å’Œç»“æœæ”¶é›†

```python
# Celery ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—è¿›è¡Œä»»åŠ¡åˆ†å‘
# - ä¸»è¿›ç¨‹å’Œå­è¿›ç¨‹éƒ½è¿æ¥æ¶ˆæ¯é˜Ÿåˆ—
# - å­è¿›ç¨‹ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
# - å­è¿›ç¨‹å°†ç»“æœå‘é€åˆ°ç»“æœåç«¯
```

---

## æºç çº§å®ç°åˆ†æ

### 1. Celery Worker è¿›ç¨‹æ± åˆ›å»º

```python
# celery/worker/__init__.py (ç®€åŒ–ç‰ˆ)

from billiard import Pool

class Worker:
    def __init__(self, app, pool_cls='prefork', concurrency=4):
        self.app = app
        self.concurrency = concurrency
        
        # åˆ›å»ºè¿›ç¨‹æ± 
        if pool_cls == 'prefork':
            self.pool = PreforkPool(processes=concurrency)
    
    def start(self):
        """å¯åŠ¨ Worker"""
        # å¯åŠ¨è¿›ç¨‹æ± 
        self.pool.start()
        
        # è¿›å…¥ä¸»å¾ªç¯
        self.main_loop()
```

### 2. Prefork Pool å®ç°

```python
# celery/concurrency/prefork.py (ç®€åŒ–ç‰ˆ)

from billiard import Pool, Process

class PreforkPool:
    def __init__(self, processes=None):
        self.processes = processes or cpu_count()
        self.pool = None
    
    def start(self):
        """å¯åŠ¨è¿›ç¨‹æ± """
        # åˆ›å»º Billiard Pool
        self.pool = Pool(
            processes=self.processes,
            initializer=self._worker_init,  # å­è¿›ç¨‹åˆå§‹åŒ–å‡½æ•°
            initargs=()  # åˆå§‹åŒ–å‚æ•°
        )
    
    def _worker_init(self):
        """å­è¿›ç¨‹åˆå§‹åŒ–"""
        # æ¯ä¸ªå­è¿›ç¨‹å¯åŠ¨æ—¶æ‰§è¡Œ
        # - é‡æ–°è¿æ¥ Redis/RabbitMQ
        # - åŠ è½½ä»»åŠ¡ä»£ç 
        # - è®¾ç½®ä¿¡å·å¤„ç†å™¨
        pass
    
    def apply_async(self, func, args=(), kwds={}):
        """å¼‚æ­¥æ‰§è¡Œä»»åŠ¡"""
        return self.pool.apply_async(func, args, kwds)
```

### 3. å­è¿›ç¨‹å·¥ä½œå¾ªç¯

```python
# celery/worker/process.py (ç®€åŒ–ç‰ˆ)

def worker_process_main():
    """Worker å­è¿›ç¨‹ä¸»å¾ªç¯"""
    # 1. åˆå§‹åŒ–
    setup_worker_process()
    
    # 2. è¿›å…¥å·¥ä½œå¾ªç¯
    while True:
        # ä»æ¶ˆæ¯é˜Ÿåˆ—è·å–ä»»åŠ¡
        task = get_task_from_queue()
        
        if task is None:
            continue
        
        # æ‰§è¡Œä»»åŠ¡
        try:
            result = execute_task(task)
            # å‘é€ç»“æœ
            send_result(task.id, result)
        except Exception as e:
            # å¤„ç†é”™è¯¯
            handle_error(task.id, e)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
        if should_restart():
            break
    
    # 3. æ¸…ç†èµ„æº
    cleanup()
```

### 4. Billiard Pool å†…éƒ¨å®ç°

```python
# billiard/pool.py (ç®€åŒ–ç‰ˆ)

class Pool:
    def __init__(self, processes=None, initializer=None, initargs=()):
        self.processes = processes
        self.initializer = initializer
        self.initargs = initargs
        self._pool = []  # è¿›ç¨‹åˆ—è¡¨
        self._inqueue = Queue()  # ä»»åŠ¡é˜Ÿåˆ—
        self._outqueue = Queue()  # ç»“æœé˜Ÿåˆ—
    
    def _create_worker_process(self):
        """åˆ›å»º Worker è¿›ç¨‹"""
        w = Process(
            target=self._worker_main,
            args=(self._inqueue, self._outqueue, self.initializer, self.initargs)
        )
        w.start()
        self._pool.append(w)
    
    def _worker_main(self, inqueue, outqueue, initializer, initargs):
        """Worker è¿›ç¨‹ä¸»å‡½æ•°"""
        # åˆå§‹åŒ–
        if initializer:
            initializer(*initargs)
        
        # å·¥ä½œå¾ªç¯
        while True:
            # ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡
            task = inqueue.get()
            
            if task is None:
                break  # é€€å‡ºä¿¡å·
            
            # æ‰§è¡Œä»»åŠ¡
            try:
                result = task.func(*task.args, **task.kwds)
                outqueue.put((task.id, result, None))
            except Exception as e:
                outqueue.put((task.id, None, e))
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. è¿›ç¨‹æ± å¤§å°ä¼˜åŒ–

```python
# æ ¹æ® CPU æ ¸å¿ƒæ•°è®¾ç½®è¿›ç¨‹æ•°
import os

cpu_count = os.cpu_count()
optimal_workers = cpu_count  # æˆ– cpu_count * 2

# Celery é…ç½®
app.conf.worker_concurrency = optimal_workers
```

### 2. è¿›ç¨‹é‡å¯ç­–ç•¥

```python
# é˜²æ­¢å†…å­˜æ³„æ¼ï¼šå®šæœŸé‡å¯è¿›ç¨‹
app.conf.worker_max_tasks_per_child = 1000

# æˆ–è®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶
app.conf.worker_max_memory_per_child = 200000  # 200 MB
```

### 3. è¿›ç¨‹é¢„åˆ›å»º

```python
# Billiard Pool æ”¯æŒè¿›ç¨‹é¢„åˆ›å»º
# é¿å…ä»»åŠ¡æ‰§è¡Œæ—¶çš„è¿›ç¨‹åˆ›å»ºå¼€é”€
pool = Pool(processes=4)  # ç«‹å³åˆ›å»º 4 ä¸ªè¿›ç¨‹
```

### 4. ä»»åŠ¡æ‰¹å¤„ç†

```python
# å‡å°‘è¿›ç¨‹é—´é€šä¿¡å¼€é”€
# å°†å¤šä¸ªå°ä»»åŠ¡åˆå¹¶ä¸ºä¸€ä¸ªå¤§ä»»åŠ¡
def batch_process(items):
    results = []
    for item in items:
        results.append(process_item(item))
    return results
```

---

## æœ€ä½³å®è·µ

### 1. åˆç†è®¾ç½®å¹¶å‘æ•°

```python
# âœ… å¥½çš„å®è·µï¼šæ ¹æ® CPU æ ¸å¿ƒæ•°è®¾ç½®
import os
cpu_count = os.cpu_count()
app.conf.worker_concurrency = cpu_count

# âŒ ä¸å¥½çš„å®è·µï¼šè®¾ç½®è¿‡é«˜çš„å¹¶å‘æ•°
app.conf.worker_concurrency = 100  # è¿‡å¤šè¿›ç¨‹ä¼šå¯¼è‡´ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€
```

### 2. é…ç½®è¿›ç¨‹é‡å¯

```python
# âœ… å¥½çš„å®è·µï¼šå®šæœŸé‡å¯è¿›ç¨‹é˜²æ­¢å†…å­˜æ³„æ¼
app.conf.worker_max_tasks_per_child = 1000

# âŒ ä¸å¥½çš„å®è·µï¼šä¸è®¾ç½®é‡å¯ç­–ç•¥
# å¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼ç´¯ç§¯
```

### 3. ä¼˜é›…å…³é—­

```python
# âœ… å¥½çš„å®è·µï¼šä½¿ç”¨ä¿¡å·ä¼˜é›…å…³é—­
# Celery è‡ªåŠ¨å¤„ç† SIGTERM å’Œ SIGINT

# âŒ ä¸å¥½çš„å®è·µï¼šç›´æ¥ kill -9
# å¯èƒ½å¯¼è‡´ä»»åŠ¡ä¸¢å¤±
```

### 4. ç›‘æ§è¿›ç¨‹çŠ¶æ€

```python
# âœ… å¥½çš„å®è·µï¼šç›‘æ§è¿›ç¨‹å¥åº·çŠ¶æ€
from celery import current_app

inspect = current_app.control.inspect()
stats = inspect.stats()

for worker, stat in stats.items():
    pool = stat.get('pool', {})
    print(f"{worker}: {pool.get('max-concurrency', 'N/A')} workers")
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **Billiard æ˜¯ Celery çš„å¤šè¿›ç¨‹ç®¡ç†å·¥å…·**
   - åŸºäº `multiprocessing` çš„ fork
   - ä¸“é—¨ä¸º Celery ä¼˜åŒ–

2. **è¿›ç¨‹æ± æœºåˆ¶**
   - ä½¿ç”¨ `fork()` ç³»ç»Ÿè°ƒç”¨åˆ›å»ºå­è¿›ç¨‹
   - ä½¿ç”¨å†™æ—¶å¤åˆ¶ï¼ˆCOWï¼‰ä¼˜åŒ–å†…å­˜ä½¿ç”¨
   - ä¸»è¿›ç¨‹ç®¡ç†ï¼Œå­è¿›ç¨‹æ‰§è¡Œä»»åŠ¡

3. **è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸ**
   - åˆ›å»ºï¼šfork() ç³»ç»Ÿè°ƒç”¨
   - ç›‘æ§ï¼šä¸»è¿›ç¨‹ç›‘æ§å­è¿›ç¨‹å¥åº·
   - é‡å¯ï¼šå®šæœŸé‡å¯é˜²æ­¢å†…å­˜æ³„æ¼
   - ç»ˆæ­¢ï¼šä¼˜é›…å…³é—­æˆ–å¼ºåˆ¶ç»ˆæ­¢

4. **è¿›ç¨‹é—´é€šä¿¡**
   - ç®¡é“ï¼šä¸»è¿›ç¨‹å’Œå­è¿›ç¨‹é€šä¿¡
   - é˜Ÿåˆ—ï¼šä»»åŠ¡å’Œç»“æœä¼ é€’
   - æ¶ˆæ¯é˜Ÿåˆ—ï¼šä»»åŠ¡åˆ†å‘å’Œç»“æœæ”¶é›†

### å…³é”®å·¥å…·å¯¹æ¯”

| å·¥å…· | ç”¨é€” | è¯´æ˜ |
|------|------|------|
| **Billiard** | å¤šè¿›ç¨‹ç®¡ç† | Celery ä½¿ç”¨çš„è¿›ç¨‹æ± å®ç° |
| **Multiprocessing** | Python æ ‡å‡†åº“ | Billiard çš„åŸºç¡€ |
| **fork()** | ç³»ç»Ÿè°ƒç”¨ | åˆ›å»ºå­è¿›ç¨‹ |
| **COW** | å†…å­˜ä¼˜åŒ– | å†™æ—¶å¤åˆ¶æœºåˆ¶ |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¹¶å‘æ•°è®¾ç½®**ï¼šç­‰äº CPU æ ¸å¿ƒæ•°
2. **è¿›ç¨‹é‡å¯**ï¼šè®¾ç½® `worker_max_tasks_per_child`
3. **å†…å­˜é™åˆ¶**ï¼šè®¾ç½® `worker_max_memory_per_child`
4. **ç›‘æ§**ï¼šå®šæœŸæ£€æŸ¥è¿›ç¨‹å¥åº·çŠ¶æ€

---

## å‚è€ƒèµ„æ–™

- [Billiard GitHub](https://github.com/celery/billiard)
- [Python Multiprocessing æ–‡æ¡£](https://docs.python.org/3/library/multiprocessing.html)
- [Celery Worker æºç ](https://github.com/celery/celery/tree/main/celery/worker)
- [PREFORK_MECHANISM.md](./PREFORK_MECHANISM.md) - Prefork æœºåˆ¶è¯¦è§£

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´ï¼š2024å¹´*
*æœ€åæ›´æ–°ï¼š2024å¹´*

