# 🔄 Celery 不同 Pool 模式下的执行流程详解

## 📋 目录
1. [Prefork 模式执行流程](#1-prefork-模式执行流程)
2. [Solo 模式执行流程](#2-solo-模式执行流程)
3. [Eventlet 模式执行流程](#3-eventlet-模式执行流程)
4. [Gevent 模式执行流程](#4-gevent-模式执行流程)
5. [对比总结](#5-对比总结)

---

## 🎯 核心问题解答

**Q: Task 到底在哪个进程执行？**

**A: 取决于 Pool 模式**:
- **Prefork**: Task 在**子进程**中执行
- **Solo**: Task 在**主进程**中执行
- **Eventlet/Gevent**: Task 在**主进程的协程**中执行

---

## 1. Prefork 模式执行流程

### 📊 进程架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        系统进程树                                 │
└─────────────────────────────────────────────────────────────────┘

进程 PID 1000 (主进程 - Manager)
│
├─ 执行: celery -A celery_app worker --pool=prefork --concurrency=4
│
├─ 加载代码:
│  ├─ celery_app.py          ← 主进程加载
│  ├─ tasks/basic_tasks.py   ← 主进程加载（代码段共享）
│  ├─ tasks/advanced_tasks.py
│  └─ tasks/realworld_tasks.py
│
├─ 初始化:
│  ├─ 连接 Redis (broker)     ← 主进程连接
│  ├─ 连接 Redis (backend)   ← 主进程连接
│  ├─ 注册信号处理器          ← 主进程处理
│  └─ 创建进程池              ← 主进程管理
│
└─ Fork 子进程 (--concurrency=4)
   │
   ├─ 子进程 PID 1001 (Worker-1)
   │  │
   │  ├─ 继承父进程的代码段（共享，只读）
   │  │  ├─ celery_app.py 代码
   │  │  └─ tasks/*.py 代码
   │  │
   │  ├─ 重新连接 Redis        ← 子进程独立连接
   │  │  ├─ broker 连接
   │  │  └─ backend 连接
   │  │
   │  ├─ 执行循环:
   │  │  1. 从队列获取任务消息  ← 子进程执行
   │  │  2. 反序列化任务参数    ← 子进程执行
   │  │  3. 调用任务函数        ← 子进程执行 ⭐ Task 在这里执行
   │  │  4. 序列化任务结果      ← 子进程执行
   │  │  5. 发送结果到 backend ← 子进程执行
   │  │
   │  └─ 任务执行示例:
   │     tasks.basic_tasks.add(3, 5)  ← 在子进程 PID 1001 中执行
   │
   ├─ 子进程 PID 1002 (Worker-2)
   │  │
   │  ├─ 继承父进程的代码段（共享，只读）
   │  ├─ 重新连接 Redis        ← 子进程独立连接
   │  │
   │  └─ 执行循环:
   │     tasks.basic_tasks.multiply(4, 6)  ← 在子进程 PID 1002 中执行
   │
   ├─ 子进程 PID 1003 (Worker-3)
   │  │
   │  └─ 执行循环:
   │     tasks.advanced_tasks.complex_task()  ← 在子进程 PID 1003 中执行
   │
   └─ 子进程 PID 1004 (Worker-4)
      │
      └─ 执行循环:
         tasks.realworld_tasks.send_email()  ← 在子进程 PID 1004 中执行
```

### 🔄 任务执行流程（详细步骤）

```
┌─────────────────────────────────────────────────────────────────┐
│                    任务提交和执行完整流程                          │
└─────────────────────────────────────────────────────────────────┘

步骤 1: 客户端提交任务
┌─────────────┐
│ Python 脚本 │  (PID 2000, 独立进程)
│             │
│ from tasks  │
│   .basic_   │
│   tasks     │
│   import    │
│   add       │
│             │
│ result =    │
│   add.delay │
│   (3, 5)    │
└──────┬──────┘
       │
       │ 1. 序列化任务
       │    - 任务名称: 'tasks.basic_tasks.add'
       │    - 参数: (3, 5)
       │    - 路由: {'queue': 'basic'}
       │
       ▼
┌─────────────┐
│   Redis     │  (消息队列)
│   Queue:    │
│   'basic'   │
│             │
│ 消息内容:    │
│ {           │
│   "task":   │
│   "tasks.   │
│   basic_    │
│   tasks.    │
│   add",     │
│   "args":   │
│   [3, 5],   │
│   "id":     │
│   "abc123"  │
│ }           │
└──────┬──────┘
       │
       │ 2. Worker 子进程从队列获取消息
       │
       ▼
┌─────────────────────────────────────────────────────────────────┐
│  子进程 PID 1001 (Worker-1)                                     │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Celery Worker 代码 (在子进程中运行)                        │  │
│  │                                                           │  │
│  │ 1. consumer.get_message()  ← 从 Redis 获取消息           │  │
│  │ 2. task.request.deserialize()  ← 反序列化参数           │  │
│  │ 3. task.run()  ← 调用任务函数 ⭐                          │  │
│  │ 4. result.serialize()  ← 序列化结果                      │  │
│  │ 5. backend.store_result()  ← 存储结果                    │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Task 代码执行 (在子进程中运行) ⭐                          │  │
│  │                                                           │  │
│  │ def add(x, y):                                            │  │
│  │     print(f"计算 {x} + {y}")  ← 在子进程 PID 1001 执行   │  │
│  │     result = x + y                                        │  │
│  │     print(f"结果: {result}")  ← 在子进程 PID 1001 执行   │  │
│  │     return result                                         │  │
│  │                                                           │  │
│  │ 执行上下文:                                                │  │
│  │ - 进程 ID: 1001                                           │  │
│  │ - 内存空间: 独立堆栈                                       │  │
│  │ - 数据库连接: 独立连接                                     │  │
│  │ - 全局变量: 独立副本（如果修改）                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│                        返回结果: 8                              │
└─────────────────────────────────────────────────────────────────┘
       │
       │ 3. 存储结果到 Redis backend
       │
       ▼
┌─────────────┐
│   Redis     │  (结果后端)
│   Backend   │
│             │
│ Key:        │
│ celery-     │
│ task-       │
│ meta-       │
│ abc123      │
│             │
│ Value:      │
│ {           │
│   "status": │
│   "SUCCESS",│
│   "result": │
│   8,        │
│   ...       │
│ }           │
└──────┬──────┘
       │
       │ 4. 客户端获取结果
       │
       ▼
┌─────────────┐
│ Python 脚本 │  (PID 2000)
│             │
│ result.get()│  ← 从 Redis 获取结果
│ # 返回: 8   │
└─────────────┘
```

### 📝 代码执行位置说明

| 代码类型 | 执行位置 | 说明 |
|---------|---------|------|
| **Celery Worker 主进程代码** | 主进程 (PID 1000) | 进程管理、信号处理、日志聚合 |
| **Celery Worker 子进程代码** | 子进程 (PID 1001-1004) | 任务获取、反序列化、结果序列化 |
| **Task 函数代码** | 子进程 (PID 1001-1004) | ⭐ **Task 在子进程中执行** |
| **celery_app.py** | 主进程 + 子进程 | 主进程加载，子进程继承代码段（共享） |
| **tasks/*.py** | 主进程 + 子进程 | 主进程加载，子进程继承代码段（共享） |

### 🔍 关键点

1. **Task 执行位置**: ⭐ **在子进程中执行**
2. **代码加载**: 主进程加载，子进程通过 COW 共享代码段
3. **连接独立性**: 每个子进程有独立的 Redis 连接
4. **内存隔离**: 每个子进程有独立的堆栈内存
5. **并发能力**: 4 个子进程可以同时执行 4 个任务

---

## 2. Solo 模式执行流程

### 📊 进程架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        系统进程树                                 │
└─────────────────────────────────────────────────────────────────┘

进程 PID 1000 (主进程 - 唯一进程)
│
├─ 执行: celery -A celery_app worker --pool=solo
│
├─ 加载代码:
│  ├─ celery_app.py          ← 主进程加载
│  ├─ tasks/basic_tasks.py   ← 主进程加载
│  ├─ tasks/advanced_tasks.py
│  └─ tasks/realworld_tasks.py
│
├─ 初始化:
│  ├─ 连接 Redis (broker)     ← 主进程连接
│  ├─ 连接 Redis (backend)   ← 主进程连接
│  └─ 注册信号处理器          ← 主进程处理
│
└─ 单线程执行循环:
   │
   └─ 主线程 (Thread-1)
      │
      ├─ 1. 从队列获取任务消息  ← 主进程执行
      ├─ 2. 反序列化任务参数    ← 主进程执行
      ├─ 3. 调用任务函数        ← 主进程执行 ⭐ Task 在这里执行
      ├─ 4. 序列化任务结果      ← 主进程执行
      ├─ 5. 发送结果到 backend ← 主进程执行
      │
      └─ 任务执行示例:
         tasks.basic_tasks.add(3, 5)  ← 在主进程 PID 1000 中执行
         tasks.basic_tasks.multiply(4, 6)  ← 在主进程 PID 1000 中执行（顺序）
```

### 🔄 任务执行流程（详细步骤）

```
┌─────────────────────────────────────────────────────────────────┐
│                    任务提交和执行完整流程                          │
└─────────────────────────────────────────────────────────────────┘

步骤 1: 客户端提交任务
┌─────────────┐
│ Python 脚本 │  (PID 2000, 独立进程)
│             │
│ result =    │
│   add.delay │
│   (3, 5)    │
└──────┬──────┘
       │
       │ 1. 序列化任务并发送到 Redis
       │
       ▼
┌─────────────┐
│   Redis     │  (消息队列)
│   Queue:    │
│   'basic'   │
└──────┬──────┘
       │
       │ 2. Worker 主进程从队列获取消息
       │
       ▼
┌─────────────────────────────────────────────────────────────────┐
│  主进程 PID 1000 (唯一进程)                                      │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Celery Worker 代码 (在主进程中运行)                        │  │
│  │                                                           │  │
│  │ 1. consumer.get_message()  ← 从 Redis 获取消息           │  │
│  │ 2. task.request.deserialize()  ← 反序列化参数           │  │
│  │ 3. task.run()  ← 调用任务函数 ⭐                          │  │
│  │ 4. result.serialize()  ← 序列化结果                      │  │
│  │ 5. backend.store_result()  ← 存储结果                    │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Task 代码执行 (在主进程中运行) ⭐                          │  │
│  │                                                           │  │
│  │ def add(x, y):                                            │  │
│  │     print(f"计算 {x} + {y}")  ← 在主进程 PID 1000 执行    │  │
│  │     result = x + y                                        │  │
│  │     print(f"结果: {result}")  ← 在主进程 PID 1000 执行   │  │
│  │     return result                                         │  │
│  │                                                           │  │
│  │ 执行上下文:                                                │  │
│  │ - 进程 ID: 1000 (主进程)                                  │  │
│  │ - 内存空间: 主进程堆栈                                     │  │
│  │ - 数据库连接: 主进程连接                                   │  │
│  │ - 全局变量: 主进程全局变量                                 │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│                        返回结果: 8                              │
│                                                                 │
│  ⚠️ 注意: 任务顺序执行，无法并发                                │
│     任务 1 完成后，才能执行任务 2                               │
└─────────────────────────────────────────────────────────────────┘
       │
       │ 3. 存储结果到 Redis backend
       │
       ▼
┌─────────────┐
│   Redis     │  (结果后端)
│   Backend   │
└──────┬──────┘
       │
       │ 4. 客户端获取结果
       │
       ▼
┌─────────────┐
│ Python 脚本 │  (PID 2000)
│             │
│ result.get()│  ← 从 Redis 获取结果
│ # 返回: 8   │
└─────────────┘
```

### 📝 代码执行位置说明

| 代码类型 | 执行位置 | 说明 |
|---------|---------|------|
| **Celery Worker 代码** | 主进程 (PID 1000) | 所有 Worker 逻辑在主进程 |
| **Task 函数代码** | 主进程 (PID 1000) | ⭐ **Task 在主进程中执行** |
| **celery_app.py** | 主进程 (PID 1000) | 主进程加载 |
| **tasks/*.py** | 主进程 (PID 1000) | 主进程加载 |
| **子进程** | ❌ 不存在 | Solo 模式没有子进程 |

### 🔍 关键点

1. **Task 执行位置**: ⭐ **在主进程中执行**
2. **进程数**: 只有 1 个进程（主进程）
3. **并发能力**: ❌ 无法并发，任务顺序执行
4. **适用场景**: 仅用于调试和开发

---

## 3. Eventlet 模式执行流程

### 📊 进程架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        系统进程树                                 │
└─────────────────────────────────────────────────────────────────┘

进程 PID 1000 (主进程 - 唯一进程)
│
├─ 执行: celery -A celery_app worker --pool=eventlet --concurrency=100
│
├─ 加载代码:
│  ├─ celery_app.py          ← 主进程加载
│  ├─ tasks/basic_tasks.py   ← 主进程加载
│  ├─ tasks/advanced_tasks.py
│  └─ tasks/realworld_tasks.py
│
├─ 初始化:
│  ├─ 连接 Redis (broker)     ← 主进程连接
│  ├─ 连接 Redis (backend)   ← 主进程连接
│  ├─ 注册信号处理器          ← 主进程处理
│  └─ 创建 Eventlet 协程池    ← 主进程管理
│
└─ 协程池执行循环:
   │
   └─ 主进程 (PID 1000)
      │
      ├─ 主线程 (Thread-1)
      │  │
      │  └─ Eventlet 协程池 (100 个协程槽位)
      │     │
      │     ├─ 协程 1 (Greenlet-1)
      │     │  │
      │     │  ├─ 1. 从队列获取任务消息  ← 协程执行
      │     │  ├─ 2. 反序列化任务参数    ← 协程执行
      │     │  ├─ 3. 调用任务函数        ← 协程执行 ⭐ Task 在这里执行
      │     │  ├─ 4. 序列化任务结果      ← 协程执行
      │     │  └─ 5. 发送结果到 backend ← 协程执行
      │     │
      │     │  任务执行示例:
      │     │  tasks.basic_tasks.add(3, 5)  ← 在协程 1 中执行
      │     │
      │     ├─ 协程 2 (Greenlet-2)
      │     │  │
      │     │  └─ tasks.basic_tasks.multiply(4, 6)  ← 在协程 2 中执行
      │     │
      │     ├─ 协程 3 (Greenlet-3)
      │     │  │
      │     │  └─ tasks.advanced_tasks.complex_task()  ← 在协程 3 中执行
      │     │
      │     ├─ 协程 4 (Greenlet-4)
      │     │  │
      │     │  └─ tasks.realworld_tasks.send_email()  ← 在协程 4 中执行
      │     │
      │     └─ ... (最多 100 个协程并发)
      │
      └─ ⚠️ 所有协程在同一个进程、同一个线程中运行
         ⚠️ 通过协程切换实现并发（非真正的并行）
```

### 🔄 任务执行流程（详细步骤）

```
┌─────────────────────────────────────────────────────────────────┐
│                    任务提交和执行完整流程                          │
└─────────────────────────────────────────────────────────────────┘

步骤 1: 客户端提交任务
┌─────────────┐
│ Python 脚本 │  (PID 2000, 独立进程)
│             │
│ result =    │
│   add.delay │
│   (3, 5)    │
└──────┬──────┘
       │
       │ 1. 序列化任务并发送到 Redis
       │
       ▼
┌─────────────┐
│   Redis     │  (消息队列)
│   Queue:    │
│   'basic'   │
└──────┬──────┘
       │
       │ 2. Worker 主进程从队列获取消息
       │
       ▼
┌─────────────────────────────────────────────────────────────────┐
│  主进程 PID 1000 (唯一进程)                                      │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Eventlet 协程池 (在主进程中运行)                          │  │
│  │                                                           │  │
│  │ 协程 1 (Greenlet-1):                                      │  │
│  │  1. consumer.get_message()  ← 协程执行                    │  │
│  │  2. task.request.deserialize()  ← 协程执行               │  │
│  │  3. task.run()  ← 调用任务函数 ⭐                          │  │
│  │  4. result.serialize()  ← 协程执行                        │  │
│  │  5. backend.store_result()  ← 协程执行                   │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Task 代码执行 (在协程中运行) ⭐                            │  │
│  │                                                           │  │
│  │ def add(x, y):                                            │  │
│  │     print(f"计算 {x} + {y}")  ← 在协程 1 中执行           │  │
│  │     time.sleep(1)  ← I/O 操作，协程切换                   │  │
│  │     result = x + y                                        │  │
│  │     print(f"结果: {result}")  ← 在协程 1 中执行           │  │
│  │     return result                                         │  │
│  │                                                           │  │
│  │ 执行上下文:                                                │  │
│  │ - 进程 ID: 1000 (主进程)                                  │  │
│  │ - 协程 ID: Greenlet-1                                     │  │
│  │ - 内存空间: 主进程堆栈（协程共享）                         │  │
│  │ - 数据库连接: 协程共享（需要协程安全的连接）               │  │
│  │ - 全局变量: 主进程全局变量（协程共享）                     │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│                        返回结果: 8                              │
│                                                                 │
│  ⚠️ 注意:                                                       │
│  - 所有协程在同一个进程、同一个线程中运行                       │
│  - 通过协程切换实现并发（非真正的并行）                         │
│  - 适合 I/O 密集型任务（网络请求、文件操作）                    │
│  - 不适合 CPU 密集型任务（受 GIL 限制）                       │
└─────────────────────────────────────────────────────────────────┘
       │
       │ 3. 存储结果到 Redis backend
       │
       ▼
┌─────────────┐
│   Redis     │  (结果后端)
│   Backend   │
└──────┬──────┘
       │
       │ 4. 客户端获取结果
       │
       ▼
┌─────────────┐
│ Python 脚本 │  (PID 2000)
│             │
│ result.get()│  ← 从 Redis 获取结果
│ # 返回: 8   │
└─────────────┘
```

### 📝 代码执行位置说明

| 代码类型 | 执行位置 | 说明 |
|---------|---------|------|
| **Celery Worker 代码** | 主进程 (PID 1000) | 所有 Worker 逻辑在主进程 |
| **Eventlet 协程池** | 主进程 (PID 1000) | 协程池在主进程中运行 |
| **Task 函数代码** | 主进程协程 | ⭐ **Task 在主进程的协程中执行** |
| **celery_app.py** | 主进程 (PID 1000) | 主进程加载 |
| **tasks/*.py** | 主进程 (PID 1000) | 主进程加载 |
| **子进程** | ❌ 不存在 | Eventlet 模式没有子进程 |

### 🔍 关键点

1. **Task 执行位置**: ⭐ **在主进程的协程中执行**
2. **进程数**: 只有 1 个进程（主进程）
3. **并发能力**: ✅ 可以并发（通过协程切换，最多 100 个协程）
4. **适用场景**: I/O 密集型任务（网络请求、文件操作）
5. **限制**: 不适合 CPU 密集型任务（受 GIL 限制）

---

## 4. Gevent 模式执行流程

### 📊 进程架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        系统进程树                                 │
└─────────────────────────────────────────────────────────────────┘

进程 PID 1000 (主进程 - 唯一进程)
│
├─ 执行: celery -A celery_app worker --pool=gevent --concurrency=100
│
├─ 加载代码:
│  ├─ celery_app.py          ← 主进程加载
│  ├─ tasks/basic_tasks.py   ← 主进程加载
│  ├─ tasks/advanced_tasks.py
│  └─ tasks/realworld_tasks.py
│
├─ 初始化:
│  ├─ 连接 Redis (broker)     ← 主进程连接
│  ├─ 连接 Redis (backend)   ← 主进程连接
│  ├─ 注册信号处理器          ← 主进程处理
│  └─ 创建 Gevent 协程池      ← 主进程管理
│
└─ 协程池执行循环:
   │
   └─ 主进程 (PID 1000)
      │
      ├─ 主线程 (Thread-1)
      │  │
      │  └─ Gevent 协程池 (100 个协程槽位)
      │     │
      │     ├─ 协程 1 (Greenlet-1)
      │     │  │
      │     │  ├─ 1. 从队列获取任务消息  ← 协程执行
      │     │  ├─ 2. 反序列化任务参数    ← 协程执行
      │     │  ├─ 3. 调用任务函数        ← 协程执行 ⭐ Task 在这里执行
      │     │  ├─ 4. 序列化任务结果      ← 协程执行
      │     │  └─ 5. 发送结果到 backend ← 协程执行
      │     │
      │     │  任务执行示例:
      │     │  tasks.basic_tasks.add(3, 5)  ← 在协程 1 中执行
      │     │
      │     ├─ 协程 2 (Greenlet-2)
      │     │  │
      │     │  └─ tasks.basic_tasks.multiply(4, 6)  ← 在协程 2 中执行
      │     │
      │     ├─ 协程 3 (Greenlet-3)
      │     │  │
      │     │  └─ tasks.advanced_tasks.complex_task()  ← 在协程 3 中执行
      │     │
      │     ├─ 协程 4 (Greenlet-4)
      │     │  │
      │     │  └─ tasks.realworld_tasks.send_email()  ← 在协程 4 中执行
      │     │
      │     └─ ... (最多 100 个协程并发)
      │
      └─ ⚠️ 所有协程在同一个进程、同一个线程中运行
         ⚠️ 通过协程切换实现并发（非真正的并行）
```

### 🔄 任务执行流程

Gevent 模式的执行流程与 Eventlet 模式**完全相同**，只是底层实现不同：

- **Eventlet**: 基于 `eventlet` 库
- **Gevent**: 基于 `gevent` 库（使用 `greenlet`）

两者的执行流程、代码位置、适用场景都相同。

### 📝 代码执行位置说明

| 代码类型 | 执行位置 | 说明 |
|---------|---------|------|
| **Celery Worker 代码** | 主进程 (PID 1000) | 所有 Worker 逻辑在主进程 |
| **Gevent 协程池** | 主进程 (PID 1000) | 协程池在主进程中运行 |
| **Task 函数代码** | 主进程协程 | ⭐ **Task 在主进程的协程中执行** |
| **celery_app.py** | 主进程 (PID 1000) | 主进程加载 |
| **tasks/*.py** | 主进程 (PID 1000) | 主进程加载 |
| **子进程** | ❌ 不存在 | Gevent 模式没有子进程 |

---

## 5. 对比总结

### 📊 执行位置对比表

| Pool 模式 | 进程数 | Task 执行位置 | Celery Worker 执行位置 | 并发能力 |
|----------|--------|--------------|----------------------|---------|
| **Prefork** | 主进程 + N 个子进程 | ⭐ **子进程** | 主进程（管理）+ 子进程（执行） | ✅ 真正并行（N 个进程） |
| **Solo** | 1 个主进程 | ⭐ **主进程** | 主进程 | ❌ 顺序执行 |
| **Eventlet** | 1 个主进程 | ⭐ **主进程协程** | 主进程 | ✅ 协程并发（最多 N 个协程） |
| **Gevent** | 1 个主进程 | ⭐ **主进程协程** | 主进程 | ✅ 协程并发（最多 N 个协程） |

### 🔍 详细对比

#### Prefork 模式

```
Task 执行位置: 子进程 (PID 1001-1004)
Celery 代码:   主进程 (管理) + 子进程 (执行)
内存模型:      每个子进程独立内存
连接模型:      每个子进程独立连接
适用场景:      CPU 密集型任务
```

#### Solo 模式

```
Task 执行位置: 主进程 (PID 1000)
Celery 代码:   主进程
内存模型:      主进程内存
连接模型:      主进程连接
适用场景:      调试和开发
```

#### Eventlet/Gevent 模式

```
Task 执行位置: 主进程协程 (PID 1000, Greenlet-1, 2, 3...)
Celery 代码:   主进程
内存模型:      主进程内存（协程共享）
连接模型:      主进程连接（需要协程安全）
适用场景:      I/O 密集型任务
```

### 🎯 关键要点总结

1. **Prefork**: Task 在**子进程**中执行，真正并行
2. **Solo**: Task 在**主进程**中执行，顺序执行
3. **Eventlet/Gevent**: Task 在**主进程协程**中执行，协程并发
4. **代码加载**: 所有模式都在主进程加载代码
5. **连接独立性**: Prefork 每个子进程独立连接，其他模式主进程连接

---

## 📝 实际项目示例

### 当前项目配置

```bash
# start_worker.sh
celery -A celery_app worker \
    --pool=prefork \
    --concurrency=4 \
    --queues=basic,advanced,realworld
```

### 执行流程

```
1. 主进程 (PID 1000) 启动
   ├─ 加载 celery_app.py
   ├─ 加载 tasks/basic_tasks.py
   ├─ 加载 tasks/advanced_tasks.py
   ├─ 加载 tasks/realworld_tasks.py
   └─ Fork 4 个子进程

2. 子进程 (PID 1001-1004) 启动
   ├─ 继承代码段（共享）
   ├─ 重新连接 Redis
   └─ 进入任务执行循环

3. 任务执行
   ├─ tasks.basic_tasks.add()      → 子进程 PID 1001 执行
   ├─ tasks.basic_tasks.multiply() → 子进程 PID 1002 执行
   ├─ tasks.advanced_tasks.*       → 子进程 PID 1003 执行
   └─ tasks.realworld_tasks.*      → 子进程 PID 1004 执行
```

---

## 🔗 相关文档

- [PREFORK_MECHANISM.md](./PREFORK_MECHANISM.md) - Prefork 底层机制详解
- [CELERY_EXECUTION_MODEL.md](./CELERY_EXECUTION_MODEL.md) - Celery 执行模型对比
- [TASK_WORKER_RELATIONSHIP.md](./TASK_WORKER_RELATIONSHIP.md) - 任务和 Worker 的关系

---

**现在你完全清楚了：Task 在不同 Pool 模式下的执行位置！** 🚀

