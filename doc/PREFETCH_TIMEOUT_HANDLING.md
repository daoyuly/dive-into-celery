# ⏱️ Prefetch 机制下的任务超时处理

## 📋 问题场景

**问题**: 如果 Worker 预取了 4 个任务，第一个任务超时了，后续的 3 个任务会如何处理？

---

## 🔍 核心机制

### 1. Prefetch 机制回顾

```
配置: worker_prefetch_multiplier=4, --concurrency=1

子进程预取流程:
1. 从队列获取任务1 → 放入本地缓冲区
2. 从队列获取任务2 → 放入本地缓冲区
3. 从队列获取任务3 → 放入本地缓冲区
4. 从队列获取任务4 → 放入本地缓冲区

本地缓冲区: [任务1, 任务2, 任务3, 任务4]

执行流程:
1. 从缓冲区取任务1 → 开始执行
2. 任务1 执行中...（其他任务在缓冲区等待）
3. 任务1 完成后 → 从缓冲区取任务2
4. 任务2 完成后 → 从缓冲区取任务3
5. 任务3 完成后 → 从缓冲区取任务4
```

### 2. 任务确认机制（Acknowledgment）

**关键配置**: `task_acks_late`

```python
# 默认配置（早期确认）
task_acks_late = False  # 任务开始执行时就确认

# 推荐配置（延迟确认）
task_acks_late = True   # 任务完成后才确认
```

**两种确认模式的区别**:

#### 模式 1: 早期确认（task_acks_late=False）

```
时间线:
─────────────────────────────────────────────────────

T0: Worker 从队列获取任务1 → 立即确认（ACK）
    ✅ 任务1 已从队列移除
    ⚠️  任务1 还未执行

T1: Worker 开始执行任务1
    ⚠️  如果此时 Worker 崩溃，任务1 丢失（已确认）

T2: 任务1 执行中...

T3: 任务1 超时 → 进程被终止
    ❌ 任务1 已确认，不会重新分发
    ❌ 任务1 执行失败，但无法重试
```

#### 模式 2: 延迟确认（task_acks_late=True）

```
时间线:
─────────────────────────────────────────────────────

T0: Worker 从队列获取任务1 → 不确认（未 ACK）
    ⚠️  任务1 仍在队列中（不可见状态）

T1: Worker 开始执行任务1
    ⚠️  任务1 在队列中处于"处理中"状态

T2: 任务1 执行中...

T3: 任务1 超时 → 进程被终止
    ✅ 任务1 未确认，会重新分发
    ✅ 其他 Worker 可以重新获取任务1
```

---

## 📊 超时场景详细分析

### 场景 1: 早期确认 + 任务超时

**配置**:
```python
task_acks_late = False  # 早期确认
worker_prefetch_multiplier = 4
```

**执行流程**:

```
┌─────────────────────────────────────────────────────────────────┐
│  子进程 (PID 1001)                                              │
│  ────────────────────────────────────────────────────────────   │
│                                                                 │
│  T0: 预取 4 个任务                                              │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ 本地缓冲区: [任务1, 任务2, 任务3, 任务4]                 │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  T1: 获取任务1 → 立即确认（ACK）                                │
│      ✅ 任务1 已从队列移除                                      │
│      ⚠️  任务2, 3, 4 仍在缓冲区（未确认）                      │
│                                                                 │
│  T2: 开始执行任务1                                              │
│      ⏱️  任务1 执行中...                                        │
│                                                                 │
│  T3: 任务1 超时（硬超时）                                       │
│      ❌ 主进程强制终止子进程（SIGKILL）                        │
│      ❌ 任务1 已确认，不会重新分发                             │
│      ❌ 任务1 执行失败，无法重试                                │
│      ⚠️  任务2, 3, 4 在缓冲区中丢失（进程被终止）              │
│                                                                 │
│  T4: 主进程创建新的子进程                                        │
│      ✅ 新子进程重新从队列获取任务                              │
│      ⚠️  任务2, 3, 4 需要重新获取（如果队列中还有）            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**问题**:
- ❌ 任务1 丢失（已确认但执行失败）
- ❌ 任务2, 3, 4 在缓冲区中丢失（进程被终止）
- ❌ 如果队列中任务2, 3, 4 已被其他 Worker 获取，可能丢失

**结果**: **任务丢失，无法恢复**

---

### 场景 2: 延迟确认 + 任务超时

**配置**:
```python
task_acks_late = True   # 延迟确认
task_reject_on_worker_lost = True  # Worker 丢失时拒绝任务
worker_prefetch_multiplier = 4
```

**执行流程**:

```
┌─────────────────────────────────────────────────────────────────┐
│  子进程 (PID 1001)                                              │
│  ────────────────────────────────────────────────────────────   │
│                                                                 │
│  T0: 预取 4 个任务                                              │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ 本地缓冲区: [任务1, 任务2, 任务3, 任务4]                 │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  T1: 获取任务1 → 不确认（未 ACK）                               │
│      ⚠️  任务1 仍在队列中（不可见状态）                        │
│      ⚠️  任务2, 3, 4 也在队列中（不可见状态）                  │
│                                                                 │
│  T2: 开始执行任务1                                              │
│      ⏱️  任务1 执行中...                                        │
│                                                                 │
│  T3: 任务1 超时（硬超时）                                       │
│      ❌ 主进程强制终止子进程（SIGKILL）                        │
│      ✅ 任务1 未确认，会重新分发                               │
│      ✅ 任务2, 3, 4 未确认，会重新分发                         │
│                                                                 │
│  T4: 主进程创建新的子进程                                        │
│      ✅ 新子进程重新从队列获取任务                              │
│      ✅ 任务1, 2, 3, 4 会重新分发到其他 Worker                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**优势**:
- ✅ 任务1 会重新分发（未确认）
- ✅ 任务2, 3, 4 会重新分发（未确认）
- ✅ 不会丢失任务

**结果**: **任务会重新分发，不会丢失**

---

## 🔄 详细时间线分析

### 场景：4 个任务预取，第一个任务超时

```
时间轴:
─────────────────────────────────────────────────────────────────

T0: Worker 预取 4 个任务
    Queue: [任务1, 任务2, 任务3, 任务4]
    ↓
    Worker 缓冲区: [任务1, 任务2, 任务3, 任务4]
    Queue: []（所有任务都被预取，不可见）

T1: Worker 开始执行任务1
    ⏱️  任务1 执行中...
    ⏸️  任务2, 3, 4 在缓冲区等待

T2: 任务1 执行中...（超过软超时）
    ⚠️  触发 SoftTimeLimitExceeded（如果配置了软超时）
    ⚠️  任务可以捕获异常并清理

T3: 任务1 执行中...（超过硬超时）
    ❌ 主进程强制终止子进程（SIGKILL）
    ⚠️  任务1 未完成
    ⚠️  任务2, 3, 4 未执行

T4: 主进程检测到子进程终止
    ├─ 如果 task_acks_late=False:
    │  ❌ 任务1 已确认，不会重新分发
    │  ❌ 任务2, 3, 4 在缓冲区中丢失
    │
    └─ 如果 task_acks_late=True:
       ✅ 任务1 未确认，会重新分发
       ✅ 任务2, 3, 4 未确认，会重新分发

T5: 主进程创建新的子进程
    ├─ 如果 task_acks_late=False:
    │  ⚠️  新子进程从队列获取新任务
    │  ⚠️  任务1, 2, 3, 4 可能丢失
    │
    └─ 如果 task_acks_late=True:
       ✅ 新子进程可以重新获取任务1, 2, 3, 4
       ✅ 或者任务1, 2, 3, 4 被其他 Worker 获取
```

---

## ⚙️ 配置建议

### 推荐配置（防止任务丢失）

```python
# celery_app.py
app.conf.update(
    # 延迟确认（任务完成后才确认）
    task_acks_late=True,
    
    # Worker 丢失时拒绝任务（重新分发）
    task_reject_on_worker_lost=True,
    
    # 预取数（根据任务类型调整）
    worker_prefetch_multiplier=4,  # 或更小
    
    # 超时设置
    task_soft_time_limit=240,  # 软超时
    task_time_limit=300,        # 硬超时
)
```

### 配置说明

#### 1. `task_acks_late=True`

**作用**: 任务完成后才确认，而不是开始执行时确认

**优势**:
- ✅ 任务执行失败时，可以重新分发
- ✅ Worker 崩溃时，任务不会丢失

**劣势**:
- ⚠️  如果 Worker 崩溃，任务会重新分发（可能重复执行）
- ⚠️  需要任务支持幂等性

#### 2. `task_reject_on_worker_lost=True`

**作用**: Worker 丢失时，拒绝任务并重新分发

**优势**:
- ✅ 确保任务不会丢失
- ✅ 任务会重新分发到其他 Worker

#### 3. `worker_prefetch_multiplier` 调整

**建议**:
- **CPU 密集型任务**: 1-2（避免负载不均衡）
- **I/O 密集型任务**: 4-10（提高吞吐量）
- **混合任务**: 2-4（平衡性能和可靠性）

**原因**:
- 预取数越小，任务丢失风险越小（缓冲区任务少）
- 预取数越大，吞吐量越高，但任务丢失风险越大

---

## 📝 实际示例

### 示例 1: 早期确认（不推荐）

```python
# celery_app.py
app.conf.update(
    task_acks_late=False,  # 早期确认
    worker_prefetch_multiplier=4,
)

# 问题场景
# 1. Worker 预取 4 个任务
# 2. 任务1 开始执行 → 立即确认
# 3. 任务1 超时 → 进程被终止
# 4. 结果: 任务1 丢失，任务2, 3, 4 在缓冲区中丢失
```

### 示例 2: 延迟确认（推荐）

```python
# celery_app.py
app.conf.update(
    task_acks_late=True,  # 延迟确认
    task_reject_on_worker_lost=True,
    worker_prefetch_multiplier=4,
)

# 问题场景
# 1. Worker 预取 4 个任务
# 2. 任务1 开始执行 → 不确认
# 3. 任务1 超时 → 进程被终止
# 4. 结果: 任务1, 2, 3, 4 会重新分发
```

### 示例 3: 任务中处理超时

```python
from celery.exceptions import SoftTimeLimitExceeded

@app.task(
    bind=True,
    soft_time_limit=240,
    time_limit=300,
    acks_late=True
)
def my_task(self, data):
    try:
        # 任务逻辑
        process_data(data)
        
        # 定期检查是否超时
        for i in range(1000000):
            if self.is_aborted():
                # 保存中间状态
                save_checkpoint(i)
                return "任务已中断"
            
            process_item(i)
            
            # 更新进度
            self.update_state(
                state='PROGRESS',
                meta={'current': i, 'total': 1000000}
            )
        
        return "任务完成"
    
    except SoftTimeLimitExceeded:
        # 优雅处理超时
        self.update_state(
            state='FAILURE',
            meta={'error': '任务超时，已保存中间状态'}
        )
        # 保存中间状态
        save_checkpoint()
        # 清理资源
        cleanup()
        raise  # 重新抛出异常，标记任务失败
```

---

## 🎯 关键要点总结

### 1. 任务确认时机

| 配置 | 确认时机 | 超时后任务状态 | 推荐度 |
|------|---------|---------------|--------|
| `task_acks_late=False` | 任务开始执行时 | ❌ 已确认，不会重新分发 | ⚠️  不推荐 |
| `task_acks_late=True` | 任务完成后 | ✅ 未确认，会重新分发 | ✅ 推荐 |

### 2. 超时后的处理

**早期确认（task_acks_late=False）**:
- ❌ 任务1 丢失（已确认但执行失败）
- ❌ 任务2, 3, 4 在缓冲区中丢失（进程被终止）
- ❌ 无法恢复

**延迟确认（task_acks_late=True）**:
- ✅ 任务1 会重新分发（未确认）
- ✅ 任务2, 3, 4 会重新分发（未确认）
- ✅ 可以恢复

### 3. 最佳实践

```python
# 推荐配置
app.conf.update(
    # 延迟确认
    task_acks_late=True,
    
    # Worker 丢失时拒绝任务
    task_reject_on_worker_lost=True,
    
    # 合理的预取数
    worker_prefetch_multiplier=2,  # CPU 密集型
    # worker_prefetch_multiplier=4,  # I/O 密集型
    
    # 超时设置
    task_soft_time_limit=240,
    task_time_limit=300,
)
```

### 4. 任务设计建议

- ✅ **任务幂等性**: 支持重复执行
- ✅ **超时处理**: 捕获 `SoftTimeLimitExceeded` 异常
- ✅ **状态保存**: 定期保存中间状态
- ✅ **资源清理**: 在超时处理中清理资源

---

## 🔗 相关文档

- [TASK_DISTRIBUTION.md](./TASK_DISTRIBUTION.md) - 任务分配机制
- [CELERY_CONFIG.md](./CELERY_CONFIG.md) - 配置详解
- [TASK_WORKER_RELATIONSHIP.md](./TASK_WORKER_RELATIONSHIP.md) - 任务和 Worker 的关系

---

**总结**: 使用 `task_acks_late=True` 可以确保超时任务会重新分发，不会丢失。但需要注意任务幂等性，避免重复执行导致的问题。 🚀

